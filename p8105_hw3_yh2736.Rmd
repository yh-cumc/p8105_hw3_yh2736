---
title: "p8105_hw3_yh"
author: "Yongmei Huang"
date: "10/9/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(ggplot2)
```

# Problem 1
## Figure out the total aisles number and important production of each aisles
```{r, instacart, echo = FALSE}
#Upload the "instacart dataset
library(p8105.datasets)
data("instacart")
#check the file size of dataset instacart
object.size(instacart)

#review the variable
str(instacart)

#check the dataset
summary(instacart)

#review the first 8 observations
head(instacart, 8)

```

Dataset instacart has a size of 108695344 byte , about 103.66MB. It contains 1384617 observations and 15 variables, including order_id, product_id, add_to_cart_order, reordered, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order, product_name, aisle_id, department_id and aisle. As an example, the first order (order_id = 1, user_id = 112108) includes 8 products (product_id), and the sequence of adding the products to the cart was label from 1 to 8. Among all of 8 orders, 4 of them were reorded and 4 were first ordered. The evaluation set was at the train. It was thursday 10am when the products were placed into orders.Days since prior order to current order was 9 days. Theight products include Yogurt, organic 4% milk fat whole milk cottage cheese, celery hearts, cucumber, sardines, bananas, avocado, and the whole string cheese. 


```{r, echo = FALSE}
##aisles counters
aisle_dataset <- instacart %>% 
  janitor::clean_names() %>% 
  group_by(aisle) %>% 
  summarize(
    aisle_count = n()
  ) %>% 
  arrange(desc(aisle_count)) %>%           ##according orderd quantity descending arrange the aisle
  select(aisle, aisle_count)               ##select "aisle" and "aisle_count" variable

aisle_dataset                              ##display the counted aisle

```

There are 134 aisles, and the top 3 aisles is "fresh vegetables", "fresh fruits" and "packaged vegetables fruits" with the ordered items of 150609, 150473 and 78493, respectively. 

## A plot to show the ordered number in each aisles which ordered times > 10000
```{r, echo = FALSE}
##plot aisle which ordered item larger than 10000
aisle_dataset %>% 
  filter(aisle_count > 10000) %>% 
  ggplot(aes(x = reorder(aisle, aisle_count), y = aisle_count)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Number of productions ordered from each aisles",
    x = "aisle identification",
    y = "order numbers",
    caption = "data from https://www.instacart.com/datasets/grocery-shopping-2017"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 15, 
                              face = "bold",
                              color = "blue")
  )

```

## A table to show top3 popular productions in 3 aisles
```{r, echo = FALSE}
##setup aisle filter factor
aisle_filter_factor <- c("baking ingredients", 
                         "dog food care", 
                         "packaged vegetables fruits")

##selected three most important items in each aisles
three_import_item_dataset <- instacart %>% 
  group_by(
    aisle, product_name
  ) %>%                                                
  summarize(
    production_order_times = n()
  ) %>% 
  filter(aisle %in% aisle_filter_factor) %>%         ##filter 3 aisles
  arrange(desc(production_order_times)) %>%          ##descending ording based on order times
  group_by(aisle) %>% 
  slice(1:3)                                         ##filter the top3 items

knitr::kable(three_import_item_dataset, 
             align = c(rep('c', time = 3)), 
             caption = "top3 popular production in 3 aisles")    ##using a table to display the output

```


## A table to show order time of 2 items in each day
```{r, echo = FALSE, warning=FALSE}
##display a table to show the ordered time of two production on each day of the week

##setup the filter factor with "Pink Lady Apples" and "Coffee Ice Cream"
production_filter <- c("Pink Lady Apples", "Coffee Ice Cream")

##based on the production name to calculate the mean order time
mean_order_time <- instacart %>% 
  select(order_dow, order_hour_of_day, product_name) %>% 
  filter(product_name %in% production_filter) %>%        ## filter two items
  group_by(order_dow, product_name) %>% 
  summarize(
    mean_order_hour = round(mean(order_hour_of_day), 
                            digits = 0)
  ) %>%                                                  ##caculate mean oder time of two item
  pivot_wider(
    names_from = "product_name",
    values_from = "mean_order_hour"
  ) %>% 
  mutate(
    day_of_week = wday(order_dow + 1, 
                       label = TRUE) 
  ) %>%                                                  ##add a new col convert number to weekday     
  janitor::clean_names() %>% 
  select(day_of_week, coffee_ice_cream, pink_lady_apples, order_dow) %>% 
  pivot_longer(
    coffee_ice_cream:pink_lady_apples,
    names_to = "production_name",
    values_to = "mean_order_time"
  ) %>%                                                  
  as_tibble()

mean_ordered_dataset <- mean_order_time %>% 
  select(day_of_week, production_name, mean_order_time) %>% 
  pivot_wider(
    names_from = "day_of_week",
    values_from = "mean_order_time"
  )

knitr::kable(mean_ordered_dataset, 
             align = c(rep('c', time = 8)), 
             caption = "mean order time of two production on each day of a week")

```

# Problem 2
## Tidy dataset
```{r, echo = FALSE}
#tidy the data
##setup health status filter factor
health_status_factor <- c("Poor", "Fair", "Good", "Very good", "Excellent")

##format the dataset, and then filter the data
data("brfss_smart2010")

brfss_dataset <- brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health"
  ) %>%                                          ##just select "Overall Health" topic
  filter(
    response %in% health_status_factor
  )                                              ##filter response from "Excellent" to "Poor"

##modify variable response from character to factor and 
##the same time change the order of observation value
brfss_dataset$response <- factor(brfss_dataset$response, 
                                 levels = c("Poor",
                                            "Fair",
                                            "Good",
                                            "Very good",
                                            "Excellent")
                                 )

##ordered response from "Poor" to " Excellent"
brfss_dataset = brfss_dataset[order(brfss_dataset$response, 
                                    decreasing = FALSE), ]

##brfss_dataset$response = order(brfss_dataset$response)

##check point
str(brfss_dataset$response)                       ##response is factor
head(brfss_dataset, 10)                           ##check the value of response of head 10 rows
tail(brfss_dataset, 10)                           ##check the value of response of tail 10 rows
missing(brfss_dataset)

```



## Show the states which observed more than 7 locations in 2002 and 2010
```{r, echo = FALSE}
##table the states which observed more than 7 loactions in 2002
observed_2002_dataset <- brfss_dataset %>% 
  select(year, locationabbr, locationdesc) %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    desc_total = n()
  ) %>% 
  filter(year == 2002, desc_total >= 7)

knitr::kable(observed_2002_dataset, 
             align = c(rep('c', time = 3)), 
             caption = "States which observed more than 7 locations in 2002")

```



```{r, echo = FALSE}
##table the states which observed time more than 7 locations in 2010
observed_2010_dataset <- brfss_dataset %>% 
  select(year, locationabbr, locationdesc) %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    desc_total = n()
  ) %>% 
  filter(year == 2010, desc_total >= 7)

knitr::kable(observed_2010_dataset, 
             align = c(rep('c', time = 3)), 
             caption = "States which observed more than 7 locations in 2010")

```

```{r, echo = FALSE}
##statistic the states number of 2002 and 2010
count(observed_2002_dataset)
count(observed_2010_dataset)
```

In 2002, there are 36 states which observed 7 or more loactions. In 2010, the number of states which observed 7 or more loaction was 45.

## A plot to show mean value during period of each states

```{r, echo = FALSE}
##filter the response with "excellent"
exclt_resp_dataset <- brfss_dataset %>% 
  filter(response == "Excellent") %>% 
  select(year, locationabbr, data_value) %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    mean_data_value = mean(data_value, na.rm = TRUE)
  ) 

ggplot(exclt_resp_dataset, aes(x = year, y = mean_data_value)) +
  geom_line(aes(group = locationabbr), color = "blue") +
  geom_point(aes(color = locationabbr)) +
    labs(
    title = "mean data value of different states in year 2002~2010",
    x = "Year",
    y = "Mean Data Value",
    caption = "data from https://www.instacart.com/datasets/grocery-shopping-2017"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 15, 
                              face = "bold",
                              color = "blue")
  ) 

```


## A two-panel plot to show the distribution of data value of different response in 2006 and 2010
```{r, echo = FALSE, warning = FALSE}
##2006 and 2010 data_value distibution of "Poor", "Fair", "Good", "Very good" and "Excellent"
##filter the dataset to "NY" and year 2006 and 2010
data_value_ny_2006_and_2010 <- brfss_dataset %>% 
  filter(locationabbr == "NY") %>% 
  filter(year == c("2006", "2010")) %>%  
  group_by(locationdesc)


##delete prefix "NY-"
data_value_ny_2006_and_2010$locationdesc = sapply(strsplit(
  data_value_ny_2006_and_2010$locationdesc, 
  split = "-",
  fixed = TRUE), function(x) (x[2])
)

##draw a two-plane plot which display the
##distribution of data-value in country of NY state
ggplot(data_value_ny_2006_and_2010, aes(x = response, y = data_value)) +     
  geom_col() +                                        
  facet_grid(locationdesc~year) +
  labs(
    title = "data value of different county's response of NY state in 2006 and 2010",
    x = "Data Value",
    y = "Response",
    caption = "data from https://www.cdc.gov/BRFSS/"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold", color = "blue")
  ) +
  coord_flip()


```


# Problem 3
## tidy the dataset
```{r,echo = FALSE}
accem_dataset <- read_csv(file = "./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_or_weekend = case_when(
      day == "Monday"          ~ "weekday",
      day == "Tuesday"         ~ "weekday",
      day == "Wednesday"       ~ "weekday",
      day == "Thursday"        ~ "weekday",
      day == "Friday"          ~ "weekday",
      day == "Saturday"        ~ "weekend",
      day == "Sunday"          ~ "weekend",
      TRUE                     ~ "NA"
    )
  ) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minutes",
    values_to = "measured_value",
    names_prefix = "activity_"
  )
view(accem_dataset)

##convert the viriable minutes from chr to int
accem_dataset$minutes = as.integer(accem_dataset$minutes)

##summary the dataset
str(accem_dataset)
summary(accem_dataset)
head(accem_dataset, 10)
nrow(accem_dataset)


```
In the acclerometer dataset, the study participant' physical activity were measured repeatedly at each minute and recorded as a wide format. Using pivot_longer command, the wide format was transformed to the long format.I have also created a new variable "weekday_or_weekend" to categorize the day of measurement occuring at the weekday (from Monday to Friday) or the weekend (Satuday or Sunday). The final tidy dataset includes the week of measurement (week), the day sequence of measurement (day_id), day of the week )day), the categorized weekday or weekend described above (weeksay_or_weekend), minutes of measurement (minutes) and the value at each measurement (measurement). Through this data wrangling process, the final long foramt of the data is more readable that the previous wide format. The original wide dataset includes 35 observations, and the final long dataset includes 50400 observations (=5*7*24*60).  

## Total activity of each day
```{r, echo = FALSE}
accem_day_dataset <- accem_dataset %>% 
  group_by(week, day_id) %>% 
  summarize(
    day_activity = sum(measured_value)
  )

## A table to display total activity per day
knitr::kable(accem_day_dataset, align = (rep('c', times = 3)), 
             caption = "Total activity of each day")

```

In the table, we can see the summarized activities by day, but it is hard to tell the trend through eye-balling the absolute numbers.


## Daily activity trency
```{r, echo = FALSE}
##trency of daily activity
accem_day_dataset %>% 
  ggplot(aes(x = day_id, y = day_activity, group = week, color = week)) +
  geom_line() +
  geom_point() +
  labs(
    title = "The trency of daily activity",
    x = "Day",
    y = "Activity"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 12, face = "bold", color = "blue")
  )
```
In the plot, the trend of daily activity is at a relatively higher level at the first three weeks except to the value at the second day as an outlier, compared to the value at fourth and fifth weeks.



## A plot to show daily activity for each day
```{r, echo = FALSE}
##Reorder the weekday from "Monday" to "Sunday"
accem_dataset$day <- factor(accem_dataset$day, 
                            levels = c("Monday",
                                       "Tuesday",
                                       "Wednesday",
                                       "Thursday",
                                       "Friday", 
                                       "Saturday", 
                                       "Sunday"))

accem_dataset %>% 
  ggplot(aes(x = minutes, y = measured_value, group = day_id, color = day)) +
  geom_line() +
  facet_grid(day_id~.) 

```

In this plot of measured values by minutes, we can find that the patient's physicial activity mains at a stable level on weekends (Saturday and Sunday), but fluntuates on weekdays from Monday to Friday.  


